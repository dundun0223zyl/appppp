{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2309aa5a-60fd-46f8-b0ed-3ba5cf2a67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dundun/myenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591248fd-384d-4dbc-bdb4-f88f39545d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarketAux API Key: w3El7U93SWJ9WsvI0VVNgC5tk9bC6jNHi4rVGdXe\n",
      "Alpha Vantage API Key: H6WR525VJZ11X3KP\n",
      "OpenAI API Key: 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\n",
      "FMP Key: 4JvGiOuaP3YcR8qKsqoMCTpZg94d5Eyr\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"financial_key.env\")\n",
    "\n",
    "# Access API keys securely\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "MARKETAUX_API_KEY = os.getenv(\"MARKETAUX_API_KEY\")\n",
    "FMP_KEY = os.getenv(\"FMP_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "print(\"MarketAux API Key:\", MARKETAUX_API_KEY)\n",
    "print(\"Alpha Vantage API Key:\", ALPHA_VANTAGE_API_KEY)\n",
    "print(\"OpenAI API Key:\", OPENAI_API_KEY)\n",
    "print(\"FMP Key:\", FMP_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44499be8-9a2a-41de-a116-793db89c7834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8a0abba-dcae-498b-b7d1-7f83db2b7042",
   "metadata": {},
   "source": [
    "**this is so far the final version, but still need the refinement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ec65578-d09c-4bdb-a05a-8dcb67294766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 9708 tickers from SEC.\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Query, HTTPException\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import os\n",
    "from urllib.parse import quote\n",
    "from fastapi import FastAPI\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "load_dotenv(\"financial_key.env\")\n",
    "\n",
    "# API KEYS\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "MARKETAUX_API_KEY = os.getenv(\"MARKETAUX_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# SEC Tickers Cache\n",
    "SEC_TICKERS = {}\n",
    "\n",
    "# Fetch stock tickers dynamically from SEC\n",
    "def fetch_sec_tickers():\n",
    "    \"\"\"Fetches and caches stock tickers from SEC API with retries.\"\"\"\n",
    "    global SEC_TICKERS\n",
    "    url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "    headers = {\"User-Agent\": \"your-email@example.com\"}  # Replace with your email\n",
    "\n",
    "    for attempt in range(3):  # Retry mechanism\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                SEC_TICKERS = {str(entry[\"ticker\"]).upper(): entry for entry in data.values()}\n",
    "                print(f\"✅ Successfully loaded {len(SEC_TICKERS)} tickers from SEC.\")\n",
    "                return\n",
    "            else:\n",
    "                print(f\"❌ SEC API failed with status {response.status_code}, retrying...\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"⚠️ Request error: {e}, retrying...\")\n",
    "\n",
    "        time.sleep(2)  # Wait before retrying\n",
    "\n",
    "    raise HTTPException(status_code=500, detail=\"Failed to fetch SEC tickers after retries\")\n",
    "\n",
    "# Fetch tickers on startup\n",
    "fetch_sec_tickers()\n",
    "\n",
    "# Extract stock symbol dynamically\n",
    "def extract_stock_symbol(query):\n",
    "    \"\"\"Extracts stock symbol from user query using SEC tickers.\"\"\"\n",
    "    words = query.upper().split()\n",
    "    for word in words:\n",
    "        if word in SEC_TICKERS:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "# Generic API Fetcher with error handling\n",
    "def fetch_api(url):\n",
    "    \"\"\"Fetch data from an external API with error handling.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"❌ API error: {response.status_code}\")\n",
    "            return {}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"⚠️ API request failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Company Ticker Search\n",
    "@app.get(\"/search/{keyword}\")\n",
    "def search_ticker(keyword: str):\n",
    "    \"\"\"Search for stock symbols using the SEC tickers cache.\"\"\"\n",
    "    keyword_upper = keyword.upper()  # Convert input to uppercase to match SEC tickers\n",
    "    matching_tickers = [\n",
    "        ticker for ticker in SEC_TICKERS.keys() if keyword_upper in ticker or keyword_upper in SEC_TICKERS[ticker][\"title\"].upper()\n",
    "    ]\n",
    "    \n",
    "    if not matching_tickers:\n",
    "        return {\"query\": keyword, \"message\": \"No results found in SEC tickers\"}\n",
    "\n",
    "    return {\"query\": keyword, \"matching_tickers\": matching_tickers}\n",
    "\n",
    "\n",
    "# Stock Data\n",
    "# Stock Data API\n",
    "@app.get(\"/stock/{symbol}\")\n",
    "def get_stock_data(symbol: str):\n",
    "    \"\"\"Fetch real-time stock price, historical trends, and fundamental data.\"\"\"\n",
    "\n",
    "    # Fetch real-time stock price from Alpha Vantage\n",
    "    price_url = f\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={symbol}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    price_data = fetch_api(price_url).get(\"Global Quote\", {})\n",
    "\n",
    "    print(\"Real-Time Stock Data:\", price_data)  # Debugging\n",
    "\n",
    "    # Fetch historical stock price (daily)\n",
    "    hist_url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    hist_data = fetch_api(hist_url).get(\"Time Series (Daily)\", {})\n",
    "\n",
    "    print(\"Historical Stock Data:\", hist_data)  # Debugging\n",
    "\n",
    "    # Format historical stock prices for React chart\n",
    "    historical_prices = [\n",
    "        {\"date\": date, \"close_price\": float(data[\"4. close\"])}\n",
    "        for date, data in list(hist_data.items())[:30]  # Limit to 30 days\n",
    "    ]\n",
    "\n",
    "    # Fetch additional stock data from Yahoo Finance\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        info = stock.info\n",
    "        market_cap = info.get(\"marketCap\", \"N/A\")\n",
    "        pe_ratio = info.get(\"trailingPE\", \"N/A\")\n",
    "        dividend_yield = info.get(\"dividendYield\", \"N/A\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Yahoo Finance Error: {e}\")\n",
    "        market_cap, pe_ratio, dividend_yield = \"N/A\", \"N/A\", \"N/A\"\n",
    "\n",
    "    # Return structured API response \n",
    "    return {\n",
    "        \"symbol\": symbol,\n",
    "        \"real_time_price\": price_data.get(\"05. price\", \"N/A\"),\n",
    "        \"market_cap\": market_cap,\n",
    "        \"pe_ratio\": pe_ratio,\n",
    "        \"dividend_yield\": dividend_yield,\n",
    "        \"historical_prices\": historical_prices\n",
    "    }\n",
    "\n",
    "# Company Information\n",
    "@app.get(\"/company/{symbol}\")\n",
    "def get_company_info(symbol: str):\n",
    "    # Fetch company overview\n",
    "    overview_url = f\"https://www.alphavantage.co/query?function=OVERVIEW&symbol={symbol}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    overview_data = requests.get(overview_url).json()\n",
    "\n",
    "    # Fetch financial statements\n",
    "    balance_url = f\"https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol={symbol}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    income_url = f\"https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={symbol}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    cashflow_url = f\"https://www.alphavantage.co/query?function=CASH_FLOW&symbol={symbol}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "\n",
    "    balance_data = requests.get(balance_url).json().get(\"annualReports\", [])\n",
    "    income_data = requests.get(income_url).json().get(\"annualReports\", [])\n",
    "    cashflow_data = requests.get(cashflow_url).json().get(\"annualReports\", [])\n",
    "\n",
    "    return {\n",
    "        \"symbol\": symbol,\n",
    "        \"company_name\": overview_data.get(\"Name\"),\n",
    "        \"industry\": overview_data.get(\"Industry\"),\n",
    "        \"market_cap\": overview_data.get(\"MarketCapitalization\"),\n",
    "        \"financials\": {\n",
    "            \"balance_sheet\": balance_data[0] if balance_data else None,\n",
    "            \"income_statement\": income_data[0] if income_data else None,\n",
    "            \"cash_flow\": cashflow_data[0] if cashflow_data else None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Financial News & Sentiment\n",
    "@app.get(\"/news/{symbol}\")\n",
    "def get_financial_news(symbol: str):\n",
    "    news_url = f\"https://api.marketaux.com/v1/news/all?symbols={symbol}&api_token={MARKETAUX_API_KEY}\"\n",
    "    news_data = requests.get(news_url).json()\n",
    "\n",
    "    if \"data\" not in news_data:\n",
    "        return {\"symbol\": symbol, \"error\": \"Invalid API response\"}\n",
    "\n",
    "    articles_data = news_data[\"data\"]\n",
    "\n",
    "    if not articles_data:\n",
    "        return {\"symbol\": symbol, \"articles\": \"No news available\"}\n",
    "\n",
    "    articles = []\n",
    "    for article in articles_data:\n",
    "        sentiment_score = None\n",
    "\n",
    "        # Check if 'entities' exist and extract sentiment score\n",
    "        if \"entities\" in article:\n",
    "            for entity in article[\"entities\"]:\n",
    "                if \"sentiment_score\" in entity:\n",
    "                    sentiment_score = entity[\"sentiment_score\"]\n",
    "                    break  # Take the first available sentiment score\n",
    "\n",
    "        articles.append({\n",
    "            \"title\": article.get(\"title\", \"No title available\"),\n",
    "            \"description\": article.get(\"description\", \"No description available\"),\n",
    "            \"url\": article.get(\"url\", \"\"),\n",
    "            \"published_at\": article.get(\"published_at\", \"\"),\n",
    "            \"sentiment_score\": sentiment_score if sentiment_score is not None else \"N/A\",\n",
    "        })\n",
    "\n",
    "    return {\"symbol\": symbol, \"articles\": articles}\n",
    "\n",
    "# AI Chatbot Summarization\n",
    "@app.post(\"/chatbot/\")\n",
    "def chatbot_summary(query: str = Query(..., description=\"User's input query including stock symbol\")):\n",
    "    \"\"\"AI chatbot that summarizes stock news, price trends, and sentiment analysis.\"\"\"\n",
    "    \n",
    "    # Extract stock symbol dynamically\n",
    "    extracted_symbol = extract_stock_symbol(query)\n",
    "    if not extracted_symbol:\n",
    "        return {\"query\": query, \"ai_summary\": \"No valid stock symbol detected. Please include a company name or ticker.\"}\n",
    "\n",
    "    # Fetch latest financial news\n",
    "    news_url = f\"https://api.marketaux.com/v1/news/all?symbols={extracted_symbol}&api_token={MARKETAUX_API_KEY}\"\n",
    "    news_response = fetch_api(news_url)\n",
    "    \n",
    "    latest_articles = [\n",
    "        {\"title\": article[\"title\"], \"description\": article[\"description\"]}\n",
    "        for article in news_response.get(\"data\", [])[:3]\n",
    "    ] if news_response.get(\"data\") else []\n",
    "\n",
    "    # Fetch real-time stock price\n",
    "    stock_url = f\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={extracted_symbol}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    stock_data = fetch_api(stock_url).get(\"Global Quote\", {})\n",
    "\n",
    "    # Structure the stock info properly\n",
    "    stock_info = {\n",
    "        \"symbol\": extracted_symbol,\n",
    "        \"real_time_price\": stock_data.get(\"05. price\", \"N/A\"),\n",
    "    }\n",
    "\n",
    "    # Generate AI summary with structured prompt\n",
    "    prompt = f\"\"\"\n",
    "    User Query: {query}\n",
    "\n",
    "    Latest Financial News:\n",
    "    {latest_articles}\n",
    "\n",
    "    Current Stock Price: {stock_info['real_time_price']}\n",
    "\n",
    "    Summarize key takeaways, sentiment analysis, and impact on stock price.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    # Return structured JSON for Frontend\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"symbol\": extracted_symbol,\n",
    "        \"news\": latest_articles,\n",
    "        \"stock_info\": stock_info,\n",
    "        \"ai_summary\": response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    }\n",
    "\n",
    "\n",
    "@app.get(\"/stock/{symbol}\")\n",
    "def get_stock_data(symbol: str):\n",
    "    \"\"\"Fetch real-time stock price and historical trends.\"\"\"\n",
    "    \n",
    "    # Fetch real-time stock price\n",
    "    stock = yf.Ticker(symbol)\n",
    "    try:\n",
    "        real_time_price = stock.history(period=\"1d\")[\"Close\"].iloc[-1]  # Latest closing price\n",
    "    except:\n",
    "        real_time_price = \"N/A\"\n",
    "\n",
    "    # Fetch historical stock price (Last 30 Days)\n",
    "    try:\n",
    "        end_date = datetime.today()\n",
    "        start_date = end_date - timedelta(days=30)\n",
    "        historical = stock.history(start=start_date, end=end_date)\n",
    "\n",
    "        historical_prices = [\n",
    "            {\"date\": date.strftime(\"%Y-%m-%d\"), \"close_price\": round(row[\"Close\"], 2)}\n",
    "            for date, row in historical.iterrows()\n",
    "        ]\n",
    "    except:\n",
    "        historical_prices = []\n",
    "\n",
    "    # Return structured API response \n",
    "    return {\n",
    "        \"symbol\": symbol.upper(),\n",
    "        \"real_time_price\": real_time_price,\n",
    "        \"historical_prices\": historical_prices\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acfcb768-92dc-4bde-83d1-0ed5a06e6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "from fastapi import FastAPI, Query, HTTPException\n",
    "import requests\n",
    "import os\n",
    "import openai\n",
    "import time\n",
    "from fuzzywuzzy import process\n",
    "from urllib.parse import quote\n",
    "from urllib.parse import urlencode\n",
    "import urllib.parse\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74ded75-7057-4431-bb6f-90bb450433d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 9707 tickers from SEC.\n"
     ]
    }
   ],
   "source": [
    "# FastAPI\n",
    "app = FastAPI()\n",
    "load_dotenv(\"financial_key.env\")\n",
    "\n",
    "# API KEYS\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "\n",
    "\n",
    "# SEC Tickers Cache\n",
    "SEC_TICKERS = {}\n",
    "\n",
    "# Fetch stock tickers dynamically from SEC\n",
    "def fetch_sec_tickers():\n",
    "    \"\"\"Fetches and caches stock tickers from SEC API with retries.\"\"\"\n",
    "    global SEC_TICKERS\n",
    "    url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "    headers = {\"User-Agent\": \"ucei380@ucl.ac.uk\"}  # Replace with your email\n",
    "\n",
    "    for attempt in range(3):  # Retry mechanism\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                SEC_TICKERS = {\n",
    "                    str(entry[\"ticker\"]).upper(): entry for entry in data.values()\n",
    "                }\n",
    "                print(f\"Successfully loaded {len(SEC_TICKERS)} tickers from SEC.\")\n",
    "                return\n",
    "            else:\n",
    "                print(f\"SEC API failed with status {response.status_code}, retrying...\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error: {e}, retrying...\")\n",
    "\n",
    "        time.sleep(2)  # Wait before retrying\n",
    "\n",
    "    raise HTTPException(status_code=500, detail=\"Failed to fetch SEC tickers after retries\")\n",
    "\n",
    "# Fetch tickers on startup\n",
    "fetch_sec_tickers()\n",
    "\n",
    "# Extract stock symbol dynamically with fuzzy matching\n",
    "def extract_stock_symbol(query):\n",
    "    \"\"\"Extracts stock symbol from user query using SEC tickers (fuzzy matching enabled).\"\"\"\n",
    "    query = query.upper()\n",
    "    best_match, score = process.extractOne(query, SEC_TICKERS.keys())\n",
    "    return best_match if score >= 80 else None  # Returns match if confidence is high\n",
    "\n",
    "\n",
    "# Generic API Fetcher with error handling\n",
    "def fetch_api(url):\n",
    "    \"\"\"Fetch data from an external API with error handling.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"API error: {response.status_code}\")\n",
    "            return {}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Ticker Search\n",
    "@app.get(\"/search/{keyword}\")\n",
    "def search_ticker(keyword: str):\n",
    "    \"\"\"Search for stock symbols using the SEC tickers cache with fuzzy matching.\"\"\"\n",
    "    keyword_upper = keyword.upper()\n",
    "    \n",
    "    # Fuzzy match ticker symbols\n",
    "    matching_tickers = [\n",
    "        ticker for ticker in SEC_TICKERS.keys() if keyword_upper in ticker or keyword_upper in SEC_TICKERS[ticker][\"title\"].upper()\n",
    "    ]\n",
    "    \n",
    "    if not matching_tickers:\n",
    "        return {\"query\": keyword, \"message\": \"No results found in SEC tickers\"}\n",
    "\n",
    "    return {\"query\": keyword, \"matching_tickers\": matching_tickers}\n",
    "\n",
    "# Financial News Search API\n",
    "@app.get(\"/news/\")\n",
    "def get_news(\n",
    "    query: str = Query(..., min_length=3, description=\"Company name or keyword (at least 3 characters)\"),\n",
    "    from_date: str = Query(None, description=\"Start date in YYYY-MM-DD format\"),\n",
    "    to_date: str = Query(None, description=\"End date in YYYY-MM-DD format\"),\n",
    "    sort_by: str = Query(\"publishedAt\", description=\"Sort by: relevancy, popularity, publishedAt\"),\n",
    "    sources: str = Query(None, description=\"Comma-separated sources like 'bbc-news,techcrunch'\"),\n",
    "    domains: str = Query(None, description=\"Comma-separated domains like 'bbc.co.uk,techcrunch.com'\"),\n",
    "    language: str = Query(\"en\", description=\"Language code like 'en' for English\"),\n",
    "    page_size: int = Query(10, description=\"Number of results per page, max 100\"),\n",
    "    page: int = Query(1, description=\"Page number for pagination\"),\n",
    "):\n",
    "    \"\"\"Fetch news articles based on user-defined preferences, excluding full content.\"\"\"\n",
    "    base_url = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "    # Use `urllib.parse.urlencode` to construct the query\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"from\": from_date,\n",
    "        \"to\": to_date,\n",
    "        \"sortBy\": sort_by,\n",
    "        \"sources\": sources,\n",
    "        \"domains\": domains,\n",
    "        \"language\": language,\n",
    "        \"pageSize\": page_size,\n",
    "        \"page\": page,\n",
    "        \"apiKey\": NEWS_API_KEY,\n",
    "    }\n",
    "\n",
    "    # Remove `None` values from parameters\n",
    "    params = {k: v for k, v in params.items() if v is not None}\n",
    "\n",
    "    # Build the final URL safely\n",
    "    news_url = f\"{base_url}?{urllib.parse.urlencode(params)}\"\n",
    "    \n",
    "    response = fetch_api(news_url)\n",
    "\n",
    "    if \"articles\" not in response:\n",
    "        return {\"query\": query, \"error\": \"No news found or API error\"}\n",
    "\n",
    "    # Return only necessary fields, excluding 'content'\n",
    "    articles = [\n",
    "        {\n",
    "            \"title\": article.get(\"title\", \"No Title\"),\n",
    "            \"description\": article.get(\"description\", \"No Description\"),\n",
    "            \"url\": article.get(\"url\", \"\"),\n",
    "            \"urlToImage\": article.get(\"urlToImage\", \"\"),\n",
    "            \"publishedAt\": article.get(\"publishedAt\", \"\"),\n",
    "            \"source\": article.get(\"source\", {}).get(\"name\", \"Unknown\"),\n",
    "            \"content\": article.get(\"content\", \"Content not available\"),\n",
    "        }\n",
    "        for article in response[\"articles\"]\n",
    "    ]\n",
    "\n",
    "    return {\"query\": query, \"articles\": articles}\n",
    "    \n",
    "# Fetch Company Overview & Financial Data\n",
    "@app.get(\"/company/{symbol}\")\n",
    "def get_company_info(symbol: str, details: bool = Query(False, description=\"Include financial statements?\")):\n",
    "    \"\"\"Fetch company overview from Alpha Vantage and additional metrics from Yahoo Finance.\"\"\"\n",
    "\n",
    "    base_url = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "    # Fetch **Company Overview** from Alpha Vantage\n",
    "    overview_params = urllib.parse.urlencode({\n",
    "        \"function\": \"OVERVIEW\",\n",
    "        \"symbol\": symbol,\n",
    "        \"apikey\": ALPHA_VANTAGE_API_KEY\n",
    "    })\n",
    "    overview_url = f\"{base_url}?{overview_params}\"\n",
    "    overview_data = requests.get(overview_url).json()\n",
    "\n",
    "    # Fetch Yahoo Finance Data\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    info = ticker.info\n",
    "\n",
    "    # Basic Company Info\n",
    "    company_info = {\n",
    "        \"symbol\": symbol,\n",
    "        \"company_name\": overview_data.get(\"Name\", info.get(\"longName\")),\n",
    "        \"industry\": overview_data.get(\"Industry\", info.get(\"industry\")),\n",
    "        \"sector\": overview_data.get(\"Sector\", info.get(\"sector\")),\n",
    "        \"market_cap\": overview_data.get(\"MarketCapitalization\", info.get(\"marketCap\")),\n",
    "        \"description\": overview_data.get(\"Description\", info.get(\"longBusinessSummary\")),\n",
    "        \"country\": info.get(\"country\"),\n",
    "        \"employees\": info.get(\"fullTimeEmployees\"),\n",
    "        \"website\": info.get(\"website\"),\n",
    "    }\n",
    "\n",
    "    # Key Financial Metrics (From Both Sources)\n",
    "    company_info[\"key_metrics\"] = {\n",
    "        \"revenue\": overview_data.get(\"RevenueTTM\", info.get(\"totalRevenue\")),\n",
    "        \"net_income\": overview_data.get(\"NetIncomeTTM\", info.get(\"netIncomeToCommon\")),\n",
    "        \"gross_margin\": overview_data.get(\"GrossProfitMargin\", info.get(\"grossMargins\")),\n",
    "        \"operating_margin\": overview_data.get(\"OperatingMarginTTM\", info.get(\"operatingMargins\")),\n",
    "        \"profit_margin\": overview_data.get(\"ProfitMargin\", info.get(\"profitMargins\")),\n",
    "        \"debt_to_equity\": overview_data.get(\"DebtEquityRatio\", info.get(\"debtToEquity\")),\n",
    "        \"return_on_equity\": overview_data.get(\"ReturnOnEquityTTM\", info.get(\"returnOnEquity\")),\n",
    "        \"eps\": overview_data.get(\"EPS\", info.get(\"trailingEps\")),\n",
    "        \"dividend_yield\": overview_data.get(\"DividendYield\", info.get(\"dividendYield\")),\n",
    "        \"enterprise_value\": info.get(\"enterpriseValue\"),\n",
    "    }\n",
    "\n",
    "    # If user requests financial statements, fetch from Alpha Vantage\n",
    "    if details:\n",
    "        balance_params = urllib.parse.urlencode({\n",
    "            \"function\": \"BALANCE_SHEET\",\n",
    "            \"symbol\": symbol,\n",
    "            \"apikey\": ALPHA_VANTAGE_API_KEY\n",
    "        })\n",
    "        income_params = urllib.parse.urlencode({\n",
    "            \"function\": \"INCOME_STATEMENT\",\n",
    "            \"symbol\": symbol,\n",
    "            \"apikey\": ALPHA_VANTAGE_API_KEY\n",
    "        })\n",
    "        cashflow_params = urllib.parse.urlencode({\n",
    "            \"function\": \"CASH_FLOW\",\n",
    "            \"symbol\": symbol,\n",
    "            \"apikey\": ALPHA_VANTAGE_API_KEY\n",
    "        })\n",
    "\n",
    "        balance_url = f\"{base_url}?{balance_params}\"\n",
    "        income_url = f\"{base_url}?{income_params}\"\n",
    "        cashflow_url = f\"{base_url}?{cashflow_params}\"\n",
    "\n",
    "        balance_data = requests.get(balance_url).json().get(\"annualReports\", [])\n",
    "        income_data = requests.get(income_url).json().get(\"annualReports\", [])\n",
    "        cashflow_data = requests.get(cashflow_url).json().get(\"annualReports\", [])\n",
    "\n",
    "        company_info[\"financials\"] = {\n",
    "            \"balance_sheet\": balance_data[0] if balance_data else None,\n",
    "            \"income_statement\": income_data[0] if income_data else None,\n",
    "            \"cash_flow\": cashflow_data[0] if cashflow_data else None,\n",
    "        }\n",
    "\n",
    "    return company_info\n",
    "\n",
    "\n",
    "# Text Summarization and Sentiment Analysis\n",
    "import openai\n",
    "\n",
    "def ask_gpt4_for_analysis(title, description, url, content, action):\n",
    "    \"\"\"Calls OpenAI GPT-4 for summary or sentiment analysis.\"\"\"\n",
    "\n",
    "    # Use available content or fallback to title + description\n",
    "    content_to_use = content if content and content != \"Content not available\" else f\"{title} - {description}\"\n",
    "\n",
    "    # Define different prompts for summary & sentiment\n",
    "    if action == \"summary\":\n",
    "        prompt = f\"\"\"\n",
    "        You are a financial analyst with expertise in market trends and stock performance.\n",
    "        Summarize the following news article while focusing on:\n",
    "        \n",
    "        ### **Main Event or Topic Discussed**\n",
    "        - Provide a concise overview of the key event.\n",
    "        \n",
    "        ### **Key Takeaways and Market Impact**\n",
    "        - Identify any financial or market-related consequences.\n",
    "        - If applicable, predict how this event may influence stock performance or industry sentiment.\n",
    "        \n",
    "        ### **Reactions from Investors, Companies, or the Public**\n",
    "        - If the article explicitly mentions responses, summarize them.\n",
    "        - If no reactions are stated, use your expertise to **predict** how investors, companies, and the public **are likely to react** based on historical trends.\n",
    "        - Provide a brief **financial analyst perspective** on the possible risks/opportunities for investors.\n",
    "        \n",
    "        **Deliver a structured, concise summary that is useful for investors and financial analysts.**\n",
    "        \n",
    "        Title: {title}\n",
    "        Description: {description}\n",
    "        Content: {content}\n",
    "        URL: {url}\n",
    "        \n",
    "        Format your response professionally, with bullet points for clarity.\n",
    "        \"\"\"\n",
    "\n",
    "    elif action == \"sentiment\":\n",
    "        prompt = f\"\"\"\n",
    "        You are a financial analyst specializing in market sentiment and stock performance.\n",
    "        Analyze the sentiment of the following news article based on the financial impact and investor perception.\n",
    "\n",
    "        Sentiment Analysis\n",
    "        - Classify the sentiment as **Positive, Negative, or Neutral.\n",
    "        - Justify the classification with key phrases from the article.\n",
    "\n",
    "        Key Factors Influencing Sentiment\n",
    "        - Identify the main reasons driving this sentiment (e.g., company controversy, economic factors, stock volatility).\n",
    "        - Compare with similar past events and their market impact.\n",
    "\n",
    "        Market Impact & Investor Behavior\n",
    "        - Explain how this event may influence stock price, investor confidence, and public sentiment.\n",
    "        - Discuss potential risks or opportunities for investors.\n",
    "\n",
    "        Investment Perspective\n",
    "        - Provide a financial analyst’s take on whether this event could create buying opportunities, short-term risks, or long-term concerns.\n",
    "        - Offer recommendations based on historical data and market trends.\n",
    "        \n",
    "        Title: {title}\n",
    "        Description: {description}\n",
    "        Content: {content}\n",
    "        URL: {url}\n",
    "        \n",
    "        Deliver an **expert-level sentiment analysis** formatted in clear sections, useful for traders, investors, and financial analysts.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    else:\n",
    "        return {\"error\": \"Invalid action\"}\n",
    "    \n",
    "    # Send request to OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a financial news analyst.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "    # ✅ Print response inside Jupyter Notebook\n",
    "        result = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(\"OpenAI Response:\", result)  # PRINT RESPONSE\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error calling OpenAI API:\", str(e))  # PRINT ERROR IF IT FAILS\n",
    "        return {\"error\": \"Failed to get response from OpenAI\"}\n",
    "    \n",
    "\n",
    "\n",
    "@app.get(\"/analyze/\")\n",
    "def analyze_news(\n",
    "    title: str = Query(..., description=\"News article title\"),\n",
    "    description: str = Query(..., description=\"News article description\"),\n",
    "    content: str = Query(..., description=\"News article content\"),\n",
    "    url: str = Query(..., description=\"News article URL\"),\n",
    "    action: str = Query(\"summary\", description=\"Choose 'summary' or 'sentiment'\")\n",
    "):\n",
    "    \"\"\"Processes news details and analyzes using OpenAI GPT-4.\"\"\"\n",
    "    \n",
    "    analysis_result = ask_gpt4_for_analysis(title, description, content, url, action)\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"description\": description,\n",
    "        \"news_url\": url,\n",
    "        \"content\": content,\n",
    "        \"action\": action,\n",
    "        \"analysis_result\": analysis_result\n",
    "    }\n",
    "\n",
    "\n",
    "# Stock Data Monitoring and Prediction\n",
    "\n",
    "# Define LSTM Model\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):\n",
    "        super(StockLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return self.fc(lstm_out[:, -1, :])\n",
    "\n",
    "# Function to Fetch and Prepare Stock Data\n",
    "def get_stock_data(symbol, lookback=60):\n",
    "    stock = yf.Ticker(symbol)\n",
    "    data = stock.history(period=\"5y\")[\"Close\"].values.reshape(-1, 1)\n",
    "\n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    # Prepare sequences for LSTM\n",
    "    sequences, labels = [], []\n",
    "    for i in range(len(data) - lookback):\n",
    "        sequences.append(data[i : i + lookback])\n",
    "        labels.append(data[i + lookback])\n",
    "\n",
    "    return torch.tensor(sequences, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32), scaler\n",
    "\n",
    "# Train LSTM Model\n",
    "def train_lstm(symbol, epochs=20, lookback=60):\n",
    "    X_train, y_train, scaler = get_stock_data(symbol, lookback)\n",
    "    \n",
    "    model = StockLSTM()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.6f}\")\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "# Predict Future Prices\n",
    "def predict_future(model, scaler, symbol, lookback=60, days_ahead=30):\n",
    "    model.eval()\n",
    "    stock = yf.Ticker(symbol)\n",
    "    data = stock.history(period=\"5y\")[\"Close\"].values.reshape(-1, 1)\n",
    "    data = scaler.transform(data)\n",
    "\n",
    "    last_sequence = torch.tensor(data[-lookback:], dtype=torch.float32).unsqueeze(0)\n",
    "    future_predictions = []\n",
    "\n",
    "    for _ in range(days_ahead):\n",
    "        with torch.no_grad():\n",
    "            next_pred = model(last_sequence).item()\n",
    "            future_predictions.append(next_pred)\n",
    "\n",
    "            # Update sequence with new predicted value\n",
    "            last_sequence = torch.cat([last_sequence[:, 1:, :], torch.tensor([[[next_pred]]])], dim=1)\n",
    "\n",
    "    # Inverse transform predictions\n",
    "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "    return future_predictions.flatten().tolist()\n",
    "\n",
    "\n",
    "# Stock Data API\n",
    "@app.get(\"/stock/{symbol}\")\n",
    "def get_stock_data_api(symbol: str):\n",
    "    \"\"\"Fetch real-time stock price, historical OHLC data, and benchmark S&P 500.\"\"\"\n",
    "\n",
    "    stock = yf.Ticker(symbol)\n",
    "    sp500 = yf.Ticker(\"^GSPC\")  # S&P 500 index\n",
    "\n",
    "    # Fetch Real-time Stock Price\n",
    "    try:\n",
    "        real_time_price = round(stock.history(period=\"1d\")[\"Close\"].iloc[-1], 2)\n",
    "        sp500_real_time = round(sp500.history(period=\"1d\")[\"Close\"].iloc[-1], 2)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching real-time price: {e}\")\n",
    "        real_time_price, sp500_real_time = \"N/A\", \"N/A\"\n",
    "\n",
    "    # Fetch 5 Years of Historical Stock Data (OHLC + Volume)\n",
    "    try:\n",
    "        end_date = datetime.today()\n",
    "        start_date = end_date - timedelta(days=5*365)  # 5 years of data\n",
    "        \n",
    "        # Fetch historical data\n",
    "        stock_hist = stock.history(start=start_date, end=end_date)\n",
    "        sp500_hist = sp500.history(start=start_date, end=end_date)\n",
    "\n",
    "        # Format Stock OHLC Data\n",
    "        historical_prices = [\n",
    "            {\n",
    "                \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "                \"open\": round(row[\"Open\"], 2),\n",
    "                \"high\": round(row[\"High\"], 2),\n",
    "                \"low\": round(row[\"Low\"], 2),\n",
    "                \"close\": round(row[\"Close\"], 2),\n",
    "                \"volume\": int(row[\"Volume\"])  # Convert to integer\n",
    "            }\n",
    "            for date, row in stock_hist.iterrows()\n",
    "        ]\n",
    "\n",
    "        # Format S&P 500 Data for Comparison\n",
    "        sp500_prices = {\n",
    "            date.strftime(\"%Y-%m-%d\"): round(row[\"Close\"], 2) \n",
    "            for date, row in sp500_hist.iterrows()\n",
    "        }\n",
    "\n",
    "        # Merge S&P 500 data with stock data for comparison\n",
    "        for entry in historical_prices:\n",
    "            date = entry[\"date\"]\n",
    "            entry[\"sp500_close\"] = sp500_prices.get(date, None)  # Add benchmark price\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching historical data: {e}\")\n",
    "        historical_prices, sp500_prices = [], {}\n",
    "\n",
    "    # Return structured API response\n",
    "    return {\n",
    "        \"symbol\": symbol.upper(),\n",
    "        \"real_time_price\": real_time_price,\n",
    "        \"sp500_real_time\": sp500_real_time,\n",
    "        \"historical_prices\": historical_prices  # Includes OHLC, Volume & S&P 500 benchmark\n",
    "    }\n",
    "\n",
    "# API Endpoint: Predict Future Stock Prices\n",
    "@app.get(\"/predict/{symbol}\")\n",
    "def predict_stock_price(symbol: str, days_ahead: int = 30):\n",
    "    \"\"\"\n",
    "    Trains an LSTM model and predicts future stock prices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Training LSTM for {symbol}...\")\n",
    "        model, scaler = train_lstm(symbol)\n",
    "        predictions = predict_future(model, scaler, symbol, days_ahead=days_ahead)\n",
    "        \n",
    "        return {\n",
    "            \"symbol\": symbol.upper(),\n",
    "            \"days_ahead\": days_ahead,\n",
    "            \"predictions\": predictions\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        return {\"error\": \"Failed to predict stock prices\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f2a2f0-9111-4091-971e-cd7ed084a95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-1' coro=<Server.serve() running at /Users/dundun/myenv/lib/python3.10/site-packages/uvicorn/server.py:68>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [16531]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:56197 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56197 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "Training LSTM for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8_/b04pl0w94mg7rjmbvrtzsd6w0000gn/T/ipykernel_16531/3303119584.py:369: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  return torch.tensor(sequences, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32), scaler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20], Loss: 0.131030\n",
      "Epoch [5/20], Loss: 0.098409\n",
      "Epoch [10/20], Loss: 0.088041\n",
      "Epoch [15/20], Loss: 0.076646\n",
      "INFO:     127.0.0.1:58507 - \"GET /predict/TSLA?days_ahead=30 HTTP/1.1\" 200 OK\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.101278\n",
      "Epoch [5/20], Loss: 0.092948\n",
      "Epoch [10/20], Loss: 0.078907\n",
      "Epoch [15/20], Loss: 0.047026\n",
      "INFO:     127.0.0.1:62370 - \"GET /predict/TSLA?days_ahead=15 HTTP/1.1\" 200 OK\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.110902\n",
      "Epoch [5/20], Loss: 0.092909\n",
      "Epoch [10/20], Loss: 0.083573\n",
      "Epoch [15/20], Loss: 0.062858\n",
      "INFO:     127.0.0.1:50272 - \"GET /predict/TSLA?days_ahead=30 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60212 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60212 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64246 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64247 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:65189 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:65190 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:49601 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:49605 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:49607 - \"GET /search/tesla HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51324 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:51332 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:53196 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:53197 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:53775 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:53776 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:53779 - \"GET /search/tesla HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54007 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:54025 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:54736 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63266 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63271 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50360 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50362 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.101120\n",
      "Epoch [5/20], Loss: 0.091935\n",
      "Epoch [10/20], Loss: 0.078606\n",
      "Epoch [15/20], Loss: 0.049982\n",
      "INFO:     127.0.0.1:52832 - \"GET /predict/TSLA?days_ahead=10 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53525 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52868 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52896 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.100031\n",
      "Epoch [5/20], Loss: 0.089136\n",
      "Epoch [10/20], Loss: 0.071029\n",
      "Epoch [15/20], Loss: 0.032169\n",
      "INFO:     127.0.0.1:55987 - \"GET /predict/TSLA?days_ahead=10 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56690 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51280 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:51285 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.104221\n",
      "Epoch [5/20], Loss: 0.093902\n",
      "Epoch [10/20], Loss: 0.082950\n",
      "Epoch [15/20], Loss: 0.061433\n",
      "INFO:     127.0.0.1:53445 - \"GET /predict/TSLA?days_ahead=10 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54153 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58130 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58130 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.100134\n",
      "Epoch [5/20], Loss: 0.090076\n",
      "Epoch [10/20], Loss: 0.072355\n",
      "Epoch [15/20], Loss: 0.032968\n",
      "INFO:     127.0.0.1:60080 - \"GET /predict/TSLA?days_ahead=30 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:65157 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:65157 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54738 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:54754 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.102645\n",
      "Epoch [5/20], Loss: 0.094939\n",
      "Epoch [10/20], Loss: 0.084779\n",
      "Epoch [15/20], Loss: 0.063930\n",
      "INFO:     127.0.0.1:55934 - \"GET /predict/TSLA?days_ahead=7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56591 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64102 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64109 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50527 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50536 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50537 - \"GET /search/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53124 - \"GET /news/?query=amazon&from_date=2025-03-10&to_date=2025-03-13&sort_by=publishedAt&language=en HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57038 - \"GET /analyze/?title=Karnataka%20Regulates%20E-Commerce%20in%20Agriculture:%20APMC%20Amendment%20Explained&description=The%20amendment%20brings%20e-commerce%20platforms%20like%20Amazon,%20Big%20Basket,%20D-Mart,%20and%20Udaan%20under%20the%20purview%20of%20the%20APMC%20market's%20licensing%20and%20cess%20requirements%20.%20%0AThe%20post%20Karnataka%20Regulates%20E-Commerce%20in%20Agriculture:%20APMC%20Amendment%20Explained%20appeared%20first%20on%20M%E2%80%A6&url=https://www.medianama.com/2025/03/223-karnataka-regulates-e-commerce-in-agriculture-with-apmc-amendment/&content=The%20Karnataka%20Assembly%20recently%20passed%20the%20Agricultural%20Produce%20Marketing%20(Regulation%20and%20Development)%20(Amendment)%20Bill,%20defining%20e-commerce%20platforms%20as%20online%20mediums%20that%20facilitate%20licensed%20trade%E2%80%A6%20%5B+4925%20chars%5D&action=summary HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51122 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:51188 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.110037\n",
      "Epoch [5/20], Loss: 0.092048\n",
      "Epoch [10/20], Loss: 0.082412\n",
      "Epoch [15/20], Loss: 0.063036\n",
      "INFO:     127.0.0.1:52026 - \"GET /predict/TSLA?days_ahead=7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52677 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.137316\n",
      "Epoch [5/20], Loss: 0.099894\n",
      "Epoch [10/20], Loss: 0.090622\n",
      "Epoch [15/20], Loss: 0.079617\n",
      "INFO:     127.0.0.1:52742 - \"GET /predict/TSLA?days_ahead=7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:49594 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56316 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:56333 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.112678\n",
      "Epoch [5/20], Loss: 0.096158\n",
      "Epoch [10/20], Loss: 0.090902\n",
      "Epoch [15/20], Loss: 0.079089\n",
      "INFO:     127.0.0.1:57636 - \"GET /predict/TSLA?days_ahead=12 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58295 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60879 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:60881 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.101631\n",
      "Epoch [5/20], Loss: 0.091757\n",
      "Epoch [10/20], Loss: 0.076779\n",
      "Epoch [15/20], Loss: 0.044727\n",
      "INFO:     127.0.0.1:62296 - \"GET /predict/TSLA?days_ahead=21 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:62975 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54619 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:54640 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.128248\n",
      "Epoch [5/20], Loss: 0.100338\n",
      "Epoch [10/20], Loss: 0.092346\n",
      "Epoch [15/20], Loss: 0.081137\n",
      "INFO:     127.0.0.1:56203 - \"GET /predict/TSLA?days_ahead=14 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56865 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55232 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:55236 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.109939\n",
      "Epoch [5/20], Loss: 0.097217\n",
      "Epoch [10/20], Loss: 0.090467\n",
      "Epoch [15/20], Loss: 0.077049\n",
      "INFO:     127.0.0.1:56626 - \"GET /predict/TSLA?days_ahead=14 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57278 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.098965\n",
      "Epoch [5/20], Loss: 0.089676\n",
      "Epoch [10/20], Loss: 0.072575\n",
      "Epoch [15/20], Loss: 0.032928\n",
      "INFO:     127.0.0.1:49815 - \"GET /predict/TSLA?days_ahead=30 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50504 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56020 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:56033 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.101252\n",
      "Epoch [5/20], Loss: 0.092218\n",
      "Epoch [10/20], Loss: 0.077970\n",
      "Epoch [15/20], Loss: 0.047107\n",
      "INFO:     127.0.0.1:57192 - \"GET /predict/TSLA?days_ahead=13 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57850 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58203 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:58209 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "Training LSTM for TSLA...\n",
      "Epoch [0/20], Loss: 0.110322\n",
      "Epoch [5/20], Loss: 0.097202\n",
      "Epoch [10/20], Loss: 0.090225\n",
      "Epoch [15/20], Loss: 0.077546\n",
      "INFO:     127.0.0.1:59366 - \"GET /predict/TSLA?days_ahead=14 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60028 - \"GET /stock/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64408 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64410 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:65399 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:65400 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:65402 - \"GET /search/apple HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50448 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50452 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:51381 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:51385 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52316 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52317 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52318 - \"GET /search/TSLA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52338 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52340 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52886 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52892 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:61541 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:61550 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:62558 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:62559 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64049 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64050 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64052 - \"GET /search/tesla HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60724 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:60725 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:61034 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:61037 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:61809 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:61811 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:61813 - \"GET /search/tesla HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53297 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:53301 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:55614 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:55615 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:55618 - \"GET /search/apple HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55622 - \"GET /company/AAPL HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60158 - \"GET /news/?query=amazon&from_date=2025-03-01&to_date=2025-03-13&sort_by=publishedAt&language=en HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57331 - \"GET /analyze/?title=Texas%20Instruments%20MSPM0C1104%20is%20the%20world%E2%80%99s%20smallest%20microcontroller%20with%20a%20size%20of%201.38mm2&description=Texas%20Instruments%20(TI)%20has%20expanded%20the%20MSPM0%20Arm%20Cortex-M0+%20MCU%20family%20with%20the%20MSPM0C1104%20which%20is%20the%20world's%20smallest%20microcontroller%20measuring%20just&url=https://www.cnx-software.com/2025/03/12/texas-instruments-mspm0c1104-is-the-worlds-smallest-microcontroller-with-a-size-of-1-38mm2/&content=Texas%20Instruments%20(TI)%20has%20expanded%20the%20MSPM0%20Arm%20Cortex-M0+%20MCU%20family%20with%20the%20MSPM0C1104%20which%20is%20the%20world%E2%80%99s%20smallest%20microcontroller%20measuring%20just%201.38mm2%20in%20its%20WCSP%20package,%20or%20about%20the%20size%E2%80%A6%20%5B+2823%20chars%5D&action=summary HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:62043 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:62044 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63501 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63502 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63520 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63526 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63719 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63721 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64167 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64168 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64170 - \"GET /search/g HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64849 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64853 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64854 - \"GET /search/g HTTP/1.1\" 200 OK\n",
      "Training LSTM for AAPL...\n",
      "Epoch [0/20], Loss: 0.158175\n",
      "Epoch [5/20], Loss: 0.132837\n",
      "Epoch [10/20], Loss: 0.121581\n",
      "Epoch [15/20], Loss: 0.102657\n",
      "INFO:     127.0.0.1:51982 - \"GET /predict/AAPL?days_ahead=16 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52659 - \"GET /stock/AAPL HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52805 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52829 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:62003 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:62008 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63247 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63251 - \"GET /tickers HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:56723 - \"GET /companies HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:56727 - \"GET /tickers HTTP/1.1\" 404 Not Found\n"
     ]
    }
   ],
   "source": [
    "# Run the API\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import asyncio\n",
    "\n",
    "# Patch event loop for Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Start Uvicorn properly in Jupyter\n",
    "config = uvicorn.Config(app, host=\"127.0.0.1\", port=8000)\n",
    "server = uvicorn.Server(config)\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task(server.serve())  # Run Uvicorn as an async task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c9a61-e09b-425a-b214-d36bf699951f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25daf4f-872d-43e8-a4c8-95a947fb600f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62e5a2-9f3e-4575-92b3-c062650fcf7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f220023-2a16-4092-9069-1a636cdc1afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12410437-e3d7-4fcf-816e-d24695aef4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/analyze/\")\n",
    "def analyze_news(\n",
    "    url: str = Query(..., description=\"URL of the news article to analyze\"),\n",
    "    action: str = Query(\"summary\", description=\"Choose 'summary', 'sentiment', or 'financial_impact'\"),\n",
    "):\n",
    "    \"\"\"Summarize, analyze sentiment, or predict financial impact of a news article using OpenAI.\"\"\"\n",
    "    \n",
    "    article = get_news_content(url)\n",
    "    if \"error\" in article:\n",
    "        return article\n",
    "\n",
    "    # **Get live & historical stock data**  \n",
    "    extracted_symbol = extract_stock_symbol(article[\"title\"])\n",
    "    stock_data = get_stock_data(extracted_symbol) if extracted_symbol else {}\n",
    "\n",
    "    # **Get company financials**\n",
    "    company_data = get_company_info(extracted_symbol) if extracted_symbol else {}\n",
    "\n",
    "    # **Choose the appropriate AI task**\n",
    "    if action == \"summary\":\n",
    "        prompt = f\"\"\"\n",
    "        Summarize the following news article while focusing on:\n",
    "        - The main event or topic discussed.\n",
    "        - The key takeaways and any financial or market impact.\n",
    "        - Any reactions from investors, companies, or the general public.\n",
    "\n",
    "        Title: {article['title']}\n",
    "        Content: {article['content']}\n",
    "\n",
    "        Provide a well-structured summary that gives useful insights to an investor or a financial analyst.\n",
    "        \"\"\"\n",
    "    \n",
    "    elif action == \"sentiment\":\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the sentiment of the following news article:\n",
    "        - Identify if the sentiment is positive, negative, or neutral.\n",
    "        - Explain why, using specific parts of the content.\n",
    "        - Assess how this news may impact the stock price of the mentioned company.\n",
    "\n",
    "        Title: {article['title']}\n",
    "        Content: {article['content']}\n",
    "\n",
    "        Provide a detailed sentiment analysis with key reasoning.\n",
    "        \"\"\"\n",
    "\n",
    "    else:  # **Financial Impact Analysis + Investment Advice**\n",
    "        prompt = f\"\"\"\n",
    "        Predict the financial impact of the following news article based on:\n",
    "        - Stock performance trends of the company.\n",
    "        - Historical stock reactions to similar events.\n",
    "        - Key company financial indicators (market cap, revenue, P/E ratio).\n",
    "\n",
    "        Title: {article['title']}\n",
    "        Content: {article['content']}\n",
    "        \n",
    "        Stock Data:\n",
    "        - Current Price: {stock_data.get('real_time_price', 'N/A')}\n",
    "        - 30-Day Trend: {stock_data.get('historical_prices', 'N/A')}\n",
    "\n",
    "        Company Financials:\n",
    "        - Market Cap: {company_data.get('market_cap', 'N/A')}\n",
    "        - P/E Ratio: {company_data.get('pe_ratio', 'N/A')}\n",
    "        - Revenue: {company_data.get('financials', {}).get('income_statement', {}).get('totalRevenue', 'N/A')}\n",
    "\n",
    "        **Investment Recommendations:**\n",
    "        1. Based on the sentiment, determine if this news is likely to increase or decrease stock value.\n",
    "        2. Compare historical stock performance under similar news conditions.\n",
    "        3. Suggest whether an investor should:\n",
    "           - **Buy** (if bullish impact is predicted)\n",
    "           - **Hold** (if neutral, but worth monitoring)\n",
    "           - **Sell or Short** (if high-risk negative impact is predicted)\n",
    "        4. Provide an explanation based on company fundamentals and market data.\n",
    "\n",
    "        Provide an **expert-level prediction** of how this news will impact the stock price in the **short-term** and **long-term**.\n",
    "        Suggest possible actions an investor could consider based on the news sentiment and company fundamentals.\n",
    "        \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"action\": action,\n",
    "        \"result\": response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c9fe7f-2f45-46ef-a1a2-6c433d869d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ config.toml file created successfully!\n"
     ]
    }
   ],
   "source": [
    "config_content = \"\"\"[theme]\n",
    "primaryColor = \"#4A3F35\"  # Dark brown\n",
    "backgroundColor = \"#EDE0D4\"  # Beige / old paper color\n",
    "secondaryBackgroundColor = \"#DDB892\"  # Light tan\n",
    "textColor = \"#3D2B1F\"  # Dark sepia\n",
    "font = \"serif\"  # Old-school serif font\n",
    "\"\"\"\n",
    "\n",
    "# Create .streamlit directory and write the file\n",
    "import os\n",
    "\n",
    "# Ensure the .streamlit directory exists\n",
    "os.makedirs(\".streamlit\", exist_ok=True)\n",
    "\n",
    "# Write the config.toml file\n",
    "with open(\".streamlit/config.toml\", \"w\") as file:\n",
    "    file.write(config_content)\n",
    "\n",
    "print(\"✅ config.toml file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955525b9-2d54-4ec5-bc44-a440f4c48464",
   "metadata": {},
   "outputs": [],
   "source": [
    "if page == \"About the Company\":\n",
    "    # 🏢 Title\n",
    "    st.markdown(\"<h1 class='stTitle'>🏢 About the Company</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "    # 📌 **Search & Ticker Selection in One Row**\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "\n",
    "    with col1:\n",
    "        company_name = st.text_input(\"Enter Company Name or Keyword\", key=\"company_input\")\n",
    "\n",
    "    with col2:\n",
    "        if company_name:\n",
    "            response = requests.get(f\"{API_BASE_URL}/search/{company_name}\")\n",
    "            if response.status_code == 200:\n",
    "                tickers = response.json().get(\"matching_tickers\", [])\n",
    "                if tickers:\n",
    "                    selected_ticker = st.selectbox(\"Select a Ticker\", tickers, key=\"ticker_select\")\n",
    "                else:\n",
    "                    st.warning(\"No matching ticker found.\")\n",
    "            else:\n",
    "                st.error(\"Failed to fetch tickers.\")\n",
    "\n",
    "    # 🏢 **Company Overview**\n",
    "    if \"selected_ticker\" in locals():\n",
    "        st.markdown(f\"<div class='header-card'>📊 {selected_ticker} Overview</div>\", unsafe_allow_html=True)\n",
    "\n",
    "        # Fetch company info from API\n",
    "        company_info = requests.get(f\"{API_BASE_URL}/company/{selected_ticker}\")\n",
    "        if company_info.status_code == 200:\n",
    "            data = company_info.json()\n",
    "\n",
    "            # ✅ **Basic Info Layout**\n",
    "            col1, col2 = st.columns([2, 3])\n",
    "\n",
    "            with col1:\n",
    "                st.markdown(f\"**Industry**: {data['industry']}\")\n",
    "\n",
    "                # ✅ Safe employees data handling\n",
    "                employees = data.get(\"employees\", \"N/A\")\n",
    "                if employees and isinstance(employees, (int, float, str)):\n",
    "                    try:\n",
    "                        employees = f\"{int(employees):,}\"\n",
    "                    except ValueError:\n",
    "                        employees = \"N/A\"\n",
    "                \n",
    "\n",
    "                st.markdown(f\"**Employees**: {employees}\")\n",
    "\n",
    "                # ✅ Ensure website is valid\n",
    "                website = data.get(\"website\", \"N/A\")\n",
    "                st.markdown(f\"**Website**: [{website}]({website})\")\n",
    "\n",
    "            with col2:\n",
    "                short_desc = data['description'][:400] + \"...\" if len(data['description']) > 400 else data['description']\n",
    "                with st.expander(\"📖 Read More\", expanded=False):\n",
    "                    st.markdown(f\"**Description:** {data['description']}\")\n",
    "                st.markdown(f\"**Description:** {short_desc}\")\n",
    "\n",
    "            \n",
    "\n",
    "            # 📌 **Market Cap Gauge Chart**\n",
    "            st.markdown(\"<div class='header-card'>🌍 Market Capitalization</div>\", unsafe_allow_html=True)\n",
    "\n",
    "            market_cap = float(data[\"market_cap\"])  # Ensure market cap is numeric\n",
    "            max_cap = 3e12  # Max scale for mega-cap companies\n",
    "\n",
    "            # Custom Vintage Colors (Muted Brown, Sepia, Aged Paper)\n",
    "            background_color = \"#F5EAD6\"  # Soft parchment color\n",
    "            gauge_colors = [\"#d9c2a3\", \"#c8ab7f\", \"#a88f5d\", \"#755c3b\"]  # Brown tones\n",
    "\n",
    "            fig = go.Figure(go.Indicator(\n",
    "                mode=\"gauge+number\",\n",
    "                value=market_cap,\n",
    "                title={\"text\": f\"{data['company_name']} Market Cap\",\n",
    "                       \"font\": {\"color\": \"#3D2B1F\"}  # Dark sepia text\n",
    "                      },\n",
    "                gauge={\n",
    "                    \"axis\": {\"range\": [0, max_cap],\n",
    "                             \"tickcolor\": \"#3D2B1F\",  # Sepia for tick labels\n",
    "                             \"tickwidth\": 2\n",
    "                            },\n",
    "                    \"bar\": {\"color\": \"#5a4632\"},  # Darkest brown for market cap\n",
    "                    \"steps\": [\n",
    "                        {\"range\": [0, 2e9], \"color\": gauge_colors[0]},   # Small-cap (Light Beige\n",
    "                        {\"range\": [2e9, 1e10], \"color\": gauge_colors[1]}, # Mid-cap (Muted Brown\n",
    "                        {\"range\": [1e10, 2e11], \"color\": gauge_colors[2]},# Large-cap (Darker Brown\n",
    "                        {\"range\": [2e11, max_cap], \"color\": gauge_colors[3]} # Mega-cap (Deep Brown)\n",
    "                    ],\n",
    "                    \"bgcolor\": background_color  # Removes the white bottom area\n",
    "                }\n",
    "            ))\n",
    "\n",
    "            # Set Figure Background to Match Theme\n",
    "            fig.update_layout(\n",
    "                paper_bgcolor=background_color,  # Matches the page's vintage background\n",
    "                font={\"color\": \"#3D2B1F\"}  # Dark sepia for text\n",
    "            )\n",
    "\n",
    "            # Display the gauge chart\n",
    "            st.plotly_chart(fig)\n",
    "\n",
    "            # 📊 **Key Financial Metrics (Styled Cards)**\n",
    "            st.markdown(\"<div class='header-card'>🔑 Key Metrics</div>\", unsafe_allow_html=True)\n",
    "\n",
    "            # Convert numbers to readable format\n",
    "            def format_large_number(value):\n",
    "                try:\n",
    "                    value = float(value)\n",
    "                    if value >= 1e9:\n",
    "                        return f\"${value / 1e9:.2f}B\"\n",
    "                    elif value >= 1e6:\n",
    "                        return f\"${value / 1e6:.2f}M\"\n",
    "                    return f\"${value:,.2f}\"\n",
    "                except:\n",
    "                    return \"N/A\"\n",
    "\n",
    "            def format_percentage(value):\n",
    "                try:\n",
    "                    return f\"{float(value) * 100:.2f}%\"\n",
    "                except:\n",
    "                    return \"N/A\"\n",
    "\n",
    "            # **Styled Metric Cards**\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "\n",
    "            with col1:\n",
    "                st.markdown(f\"<div class='metric-card'>💰 <b>Revenue</b><br>{format_large_number(data['key_metrics']['revenue'])}</div>\", unsafe_allow_html=True)\n",
    "                st.markdown(f\"<div class='metric-card'>📈 <b>Net Income</b><br>{format_large_number(data['key_metrics']['net_income'])}</div>\", unsafe_allow_html=True)\n",
    "\n",
    "            with col2:\n",
    "                st.markdown(f\"<div class='metric-card'>📊 <b>Gross Margin</b><br>{format_percentage(data['key_metrics']['gross_margin'])}</div>\", unsafe_allow_html=True)\n",
    "                st.markdown(f\"<div class='metric-card'>⚖ <b>Debt-to-Equity</b><br>{data['key_metrics']['debt_to_equity']:.2f}</div>\", unsafe_allow_html=True)\n",
    "\n",
    "            with col3:\n",
    "                st.markdown(f\"<div class='metric-card'>🏆 <b>Return on Equity</b><br>{format_percentage(data['key_metrics']['return_on_equity'])}</div>\", unsafe_allow_html=True)\n",
    "                st.markdown(f\"<div class='metric-card'>📉 <b>EPS</b><br>{data['key_metrics']['eps']}</div>\", unsafe_allow_html=True)\n",
    "\n",
    "        else:\n",
    "            st.error(\"⚠️ Could not retrieve company details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb06f9-21a2-472a-a520-7c7c76418a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "elif st.session_state.page == \"🏛 News Analysis\":\n",
    "        if  st.session_state.selected_analysis:\n",
    "            article = st.session_state.selected_analysis\n",
    "            # print(\"✅ Found selected analysis:\", article)\n",
    "    \n",
    "            st.markdown(f\"## 📊 News Analysis for: {article['title']}\")\n",
    "            st.markdown(f\"🔗 [Read Full Article]({article['url']})\")\n",
    "            st.subheader(\"📝 Article Preview\")\n",
    "            st.write(article[\"description\"])\n",
    "    \n",
    "            # Choose Analysis Type\n",
    "            analysis_type = st.radio(\"Choose Analysis Type:\", [\"Summary\", \"Sentiment\"], key=\"analysis_choice\")\n",
    "    \n",
    "            if st.button(\"Run Analysis\"):\n",
    "                st.session_state.analysis_type = analysis_type.lower()\n",
    "                \n",
    "    \n",
    "                # ✅ Send `content` in the API request\n",
    "                analysis_url = (\n",
    "                    f\"{API_BASE_URL}/analyze/?\"\n",
    "                    f\"title={article['title']}&description={article['description']}\"\n",
    "                    f\"&url={article['url']}&content={article['content']}\"\n",
    "                    f\"&action={st.session_state.analysis_type}\"\n",
    "                )\n",
    "                print(f\"✅ Calling API: {analysis_url}\")\n",
    "    \n",
    "                response = requests.get(analysis_url)\n",
    "    \n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    print(\"✅ OpenAI API Response:\", result)\n",
    "                    st.subheader(f\"📊 {analysis_type} Result\")\n",
    "                    st.write(result[\"analysis_result\"])\n",
    "                else:\n",
    "                    st.error(\"❌ Failed to analyze news.\")\n",
    "        else:\n",
    "            st.warning(\"⚠️ No article selected. Please go to 'Search News' and choose an article.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
